{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de30244-f464-45c4-b7d2-70112cee1581",
   "metadata": {},
   "source": [
    "# ADS-500B-02-FA21 {-}\n",
    "# Final Data Science Programming Project {-}\n",
    "# **Group 6: Claire Phibbs & Aaron Carr** {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5ddc4-1790-429f-ab77-24bcc1ec2bee",
   "metadata": {},
   "source": [
    "# Dataset: Bank Marketing {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494920ce-6fe3-4ce4-9e2a-62dd9f9dfbe1",
   "metadata": {},
   "source": [
    "##### **Introduction**\n",
    "For this final project, the bank_marketing.csv dataset was used to perform a secondary data analysis. This dataset provides information about marketing campaigns from a European bank. The dataset includes variables for age, job, marital status, education level, loan default status (i.e., yes/no), account balance, whether the loan is for housing (i.e., yes/no) or personal (i.e., yes/no), as well as information on the most recent bank outreach campaign, including contact method (i.e., cellular, telephone, unknown, Nan), last day of the month contaced, last month contacted, duration of last contact, number of contacts during current campaign, number of previous contacts (before the current campaign), outcome of the previous campaign, and whether the client has subscribed to a term deposit (i.e., yes/no). \\\n",
    "The goals of this project are to import and transform a raw dataset, perform exploratory and descriptive analysis, provide appropriate visualizations, and apply analytic models on the data. \\\n",
    "The main question being explored is whether one or more features--including demographics like age and education level, and previous campaign results--can be used to predict whether a bank client will take out a deposit.\n",
    "A secondary question being explored is how factors like age, marital status, education level, account balance, and loan status affect defaulting on a loan from this European bank. \\\n",
    "Logistic regression models will be used to explore the relationship between the specified independent varibales and dependent variable for each question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52fd9f-5809-43c4-a250-686a482f8725",
   "metadata": {},
   "source": [
    "#### Import libariaries for data processing & analyses {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b6999-d065-4577-a88a-3702f44874ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from textwrap import wrap\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a2d49-24d8-4144-b1fb-7babe14f8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474b824-9a5e-4099-bd2d-cabf9f55af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3efebe-dd67-4fab-b166-d0dbf6238347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R library(caTools)\n",
    "%R library(ROCR)\n",
    "%R library(car)\n",
    "%R library(rms)\n",
    "%R library(\"ggplot2\")\n",
    "%R library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824a1f5-b855-408c-8b2a-7196b0ec5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03117c-f81f-4c66-bf1c-cfde79bdb2ce",
   "metadata": {},
   "source": [
    "#### Set global variable values {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c850d9-5cd1-42b0-9362-c03d230fc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_int01 = 4\n",
    "unk_str = 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecdc5d-d1de-4df8-8754-d2e1e78f8bc7",
   "metadata": {},
   "source": [
    "## 1. Data Importing & Pre-processing {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a0191-0c41-4874-91e4-e90a866443b1",
   "metadata": {},
   "source": [
    "***\n",
    "Null Hyphothesis (H0): There is no relationship between the X variables and the Y variable (i.e., deposit). \\\n",
    "Alternative Hyphothesis (Ha): There is a relationship between the X variables and the Y variable (i.e., deposit). \\\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e02806-d948-4a1b-999e-1fdcd36e1825",
   "metadata": {},
   "source": [
    "### Initial data review {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc94099-1c74-484d-b699-bdbb0eedbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe (df) from csv file, print df\n",
    "bank_df01 = pd.read_csv('bank_marketing.csv', header=0, sep=';')\n",
    "print(bank_df01.head(10)) # display first 10 rows of df\n",
    "\n",
    "bank_df01_cols_lst01 = bank_df01.columns.values.tolist() # review column names\n",
    "\n",
    "bank_df01_len01 = len(bank_df01)\n",
    "print(f'\\n Number of df rows = {bank_df01_len01}') # display df length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043b2df-3e4c-4f10-b169-b5fcdf677199",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_df01.isnull().sum()) # review dataset for columns w/ null value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6042a2f-1230-4ca2-b786-b088fea9b41d",
   "metadata": {},
   "source": [
    "#### Initial Descriptive statistics {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e5a42-c682-464d-b80e-516ef2d14910",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = bank_df01.dtypes\n",
    "print(data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f3dc8-4c84-4c2d-83ba-00c926326777",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df01.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ead2a-5f8b-413e-ad41-632b1ca8f839",
   "metadata": {},
   "source": [
    "##### **Data Import Explanation & Dataset Characteristics**\n",
    "Initial steps included importing the bank_marketing.csv into Jupyter notebook as a pandas dataframe. The initial dataset has 45,211 rows and 17 columns (i.e., `age`, `job`, `marital`, `education`, `default`, `balance`, `housing`, `loan`, `contact`, `day`, `month`, `duration`, `campaign`, `pdays`, `previous`, `poutcome`, and `deposit`). \\\n",
    "There are a total of 4,028 missing values: `age` has 1,339 missing values; `default` has 1,306 missing values; and `contact` has 1,383 missing. The dtype command was used to see the different types of variables we are working with. \\\n",
    "The dataset contains a large number of categorical variables, including: `job`, `marital`, `education`, `default`, `housing`, `loan`, `contact`, `month`, `poutcome`, and `deposit`. The dataset also contains a few numeric variables: `age`, `balance`, `day`, `duration`, `campaign`, `pdays`, and `previous`. As `day` is ordinal, it will be treated as categorical varibale instead of discrete numerical. \\\n",
    "The describe command was also used to display the summary statistics of the numeric variables in the bank_df01 dataset. The summary statistics table shows the mean, standard deviation, min/max, and quartiles (reference table above). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32366f17-aee5-4b16-a889-22a39be8fbfe",
   "metadata": {},
   "source": [
    "### Fill in missing data & transform ambiguous values {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fefc94-ec86-46f5-966b-cb0f3e8760b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create inital boxplots for features w/ numerical values {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7757b-a1e9-46a9-bd41-8b7dab53ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for numerical variables\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20 , 20), sharey=False, sharex=False) # set figure fram\n",
    "\n",
    "axs[0, 0].boxplot(bank_df01['age'].dropna()) # subplot 1 for full dataset\n",
    "axs[0, 0].set_title('Boxplt for age')\n",
    "\n",
    "axs[0, 1].boxplot(bank_df01['balance'].dropna()) # subplot 2 for outlier dataset\n",
    "axs[0, 1].set_title('Boxplot for balance')\n",
    "\n",
    "axs[0, 2].boxplot(bank_df01['duration'].dropna()) # subplot 3 for outlier dataset\n",
    "axs[0, 2].set_title('Boxplot for duration')\n",
    "\n",
    "axs[1, 0].boxplot(bank_df01['campaign'].dropna()) # subplot 4 for outlier dataset\n",
    "axs[1, 0].set_title('Boxplot for campaign')\n",
    "\n",
    "axs[1, 1].boxplot(bank_df01['pdays'].dropna()) # subplot 5 for outlier dataset\n",
    "axs[1, 1].set_title('Boxplot for pdays')\n",
    "\n",
    "axs[1, 2].boxplot(bank_df01['previous'].dropna()) # subplot 6 for outlier dataset\n",
    "axs[1, 2].set_title('Boxplot for previous')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bc2b8-1d29-413b-8d13-909e5f6c990d",
   "metadata": {},
   "source": [
    "##### **Initial visualizaton**\n",
    "Check boxplots for numerical variables to indentify spread (varinace), and identify variables with outliers. \\\n",
    "Each one of the plots shows outliers for that variable. In order to mitigate their effects on the analyses, there will be removed. Focusing specifically on `previous` and `pdays`, the majority of values are zero based on the lack of variance, while there are also a signifacnt number of outliers. These variables will be removed, and instead a new feature will be created called `previous_contact` (yes=1/no=0) based on whether `pdays` equals -1 (client not previously contacted). \\\n",
    "Additional feature transformations are outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70073b88-e735-40ec-82fa-e4d38bd5c797",
   "metadata": {},
   "source": [
    "#### Define function: Fill in missing numerical data based on group by {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2825b0-2c49-4caa-a420-b0289d750825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_agg_sub(df, t_var=None, gb_vars=[], agg_meth='mean'):\n",
    "    '''current aggregate methods = sum, mean'''\n",
    "    if agg_meth == 'sum':\n",
    "        df_gpb01 = df.groupby(gb_vars).sum() # create a multi-indexed dataframe\n",
    "    else:\n",
    "        df_gpb01 = df.groupby(gb_vars).mean() # create a multi-indexed dataframe\n",
    "    print(df_gpb01)\n",
    "    df = pd.merge(df, df_gpb01, how='left', on=gb_vars, suffixes=(None, '_y'))\n",
    "    df[t_var] = df[t_var].fillna(value=df[t_var + '_y'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178ae8b-4ee5-4623-9309-789e98bd7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function to fill in missing age values based on group by\n",
    "bank_df01 = gb_agg_sub(bank_df01, 'age',  ['marital', 'education'])\n",
    "\n",
    "# Reset col names\n",
    "bank_df01 = bank_df01[bank_df01_cols_lst01]\n",
    "\n",
    "# Remove records where balance is less than zero\n",
    "bank_df01 = bank_df01.loc[(bank_df01['balance'] >= 0), :]\n",
    "\n",
    "# Create new feature\n",
    "bank_df01['previous_contact'] = 0\n",
    "bank_df01.loc[(bank_df01['pdays'] != -1), 'previous_contact'] = 1\n",
    "\n",
    "# Save df len for generating % loss later\n",
    "bank_df01_len02 = len(bank_df01)\n",
    "\n",
    "# Remove col not used for analysis\n",
    "bank_df01 = bank_df01.drop(['contact'], axis=1)\n",
    "bank_df01 = bank_df01.drop(['pdays'], axis=1)\n",
    "bank_df01 = bank_df01.drop(['previous'], axis=1)\n",
    "\n",
    "# Fill in `default` w/ \"unknown\" to transform it below\n",
    "bank_df01['default'] = bank_df01['default'].fillna(unk_str)\n",
    "\n",
    "print(bank_df01.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92aff50-19bd-4c61-8af1-844a08e65d9e",
   "metadata": {},
   "source": [
    "#### Define function: Transform ambigous categorical values {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06c212-0894-444f-aa69-5a49cdbac783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_mode(df, var=[(None, None, [])]):\n",
    "    '''create function to transform variable values;\n",
    "    var input uses \"column string\", \"value to transform\", \"group_by vars\" as x,y,z tuple'''\n",
    "    df_sub01 = df.dropna()\n",
    "    int_start01 = 1\n",
    "    for i, j, k in var:\n",
    "        df_sub02 = df_sub01.loc[(df_sub01[i] != j), :]\n",
    "        df_gpb01 = df_sub02.groupby(k)[i].agg(lambda x: pd.Series.mode(x)[0]).to_frame() # create a multi-indexed dataframe; add lambda fx (Stack Overflow, n.d.)\n",
    "        print(f'\\ndf_gpb01:\\n{df_gpb01}')\n",
    "        df_sub01 = pd.merge(df_sub01, df_gpb01, how='left', on=k, suffixes=(None, '_z' + str(int_start01)))\n",
    "        df_sub01.loc[(df_sub01[i] == j) & (df_sub01[i + '_z' + str(int_start01)].notna()), i] = df_sub01[i + '_z' + str(int_start01)]\n",
    "        df_sub01 = df_sub01.drop(i + '_z' + str(int_start01), axis=1)\n",
    "        int_start01 += 1\n",
    "    return df_sub01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5eb7bc-e728-4190-b7cf-d5881cf8c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df01 = cat_mode(bank_df01, [('job', unk_str, ['marital', 'education']), ('education', unk_str, ['job', 'age']), ('default', unk_str, ['job', 'marital', 'education'])])\n",
    "\n",
    "print(f'\\nbank_df01:\\n{bank_df01.head(10)}') # Review transformed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6df0a-daf9-43e9-8386-b86a794e9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-review dataset for columns w/ null value\n",
    "print(bank_df01.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c89a22-5494-4d1c-bf15-31e988fe13ad",
   "metadata": {},
   "source": [
    "##### **Explanation for filling in missing data**\n",
    "In this dataset there are missing values for three of the variables (`age`, `default`, and `contact`). To handle the missing values for the `age` column we have used the groupby command to create a multi-indexed dataframe with the imputed `age` values. Basically, the marital status and education level columns are used to impute a value for `age`. The groupby command groups similar values together and takes a mean. The imputed values for `age` is then calculated by grouping similar attributes together and filling in the age column with the mean from the grouped `marital` and `education` columns. These imputed `age` values are in column `age_y` of the dataset. \\\n",
    "To handle the missing values for `contact`, we have decided to just remove the entire column. This decision was made due to the nature of our study questions. Since it is believed that the `contact` variable is not used to predict either default status or deposit decision, it is unnecssary to fill in the missing values or include them in the dataset at all. Instead they have been removed as to not introduce more bias into the dataset by imputing the values ourselves. \\\n",
    "The default column also has some missing values. A similar process was performed to fill in the missing data as with `age`, but for this variable the groupby was done using the following variables: `job`, `marital`, `education`. \\\n",
    "Also, something to note; we have decided to remove the rows in the balance column, where the balance is less than zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6091b177-2310-4f24-b324-41c6c8387ef7",
   "metadata": {},
   "source": [
    "## 2. Data Analysis & Visualizations {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ac617-c3f5-42b4-b385-0853f89d6dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create boxplots for remaining features w/ numerical values {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301fe4b-2e38-470e-94f9-e6e27e59c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for numerical variables\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20 , 20), sharey=False, sharex=False) # set figure fram\n",
    "\n",
    "axs[0, 0].boxplot(bank_df01['age'].dropna()) # subplot 1 for full dataset\n",
    "axs[0, 0].set_title('Boxplt for age')\n",
    "\n",
    "axs[0, 1].boxplot(bank_df01['balance'].dropna()) # subplot 2 for outlier dataset\n",
    "axs[0, 1].set_title('Boxplot for balance')\n",
    "\n",
    "axs[1, 0].boxplot(bank_df01['duration'].dropna()) # subplot 3 for outlier dataset\n",
    "axs[1, 0].set_title('Boxplot for duration')\n",
    "\n",
    "axs[1, 1].boxplot(bank_df01['campaign'].dropna()) # subplot 4 for outlier dataset\n",
    "axs[1, 1].set_title('Boxplot for campaign')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65311096-f47a-4d79-adab-6adf165c49a3",
   "metadata": {},
   "source": [
    "##### **Interpretation of Boxplots**\n",
    "Above, boxplots have been created for four numerical variables in the dataset. This has been done, mainly to show the distribution of the data and to visualize outliers in the dataset. The boxplot for age shows that there is a relatively normal distribution, with outliers steming from the upper whisker. The boxplot for balance displays a highly skewed distribution with many outliers steming from the upper whisker. The balance variable also has a relatively small interquartile range compared to the other variables. The boxplot for duration displays a skewed distribution with many outliers steming from the upper whisker, and a mid-sized range compared to the other variables in the dataset. The boxplot for campaign also has a highly skewed distribution with many outliers steming from the upper whisker. Note that all of the boxplots are displayed ablove. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a95c87-c366-463c-8e79-a811c588e3e4",
   "metadata": {},
   "source": [
    "#### Define function: Remove outliers {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576a0b6-e344-432a-95c4-ecdc1b5f7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to generate comparison boxplots\n",
    "def box_comp(df, var=[(None, 1.5)]):\n",
    "    '''create function to id outliers & generate compartive boxplots;\n",
    "    var input uses column string & outlier threshold as x,y tuple'''\n",
    "    df_sub01 = df.dropna()\n",
    "    df_sub01['outlier'] = 0 \n",
    "    for i, j in var:\n",
    "        q3, q1 = np.percentile(df_sub01[i], [75, 25]) # calculate quartiles 1 & 3\n",
    "        iqr = q3 - q1 # calculate interquartile range\n",
    "        print('\\nIQR: {}-{} = {}'.format(round(q1, 4),round(q3, 4),round(iqr, 4))) # display IQR\n",
    "\n",
    "        iqr_out = iqr * j # calculate outlier threshold\n",
    "        otlr_low = q1 - iqr_out # calculate lower outlier limit\n",
    "        otlr_high = q3 + iqr_out # calculate upper outlier limit\n",
    "        df_sub01_sub1 = df_sub01.loc[(df_sub01[i] < otlr_low) | (df_sub01[i] > otlr_high)] # use .loc method to search for records that are outliers; assign to new dataframe\n",
    "        df_sub01_sub2 = df_sub01.loc[(df_sub01[i] >= otlr_low) & (df_sub01[i] <= otlr_high)] # use .loc method to search for records that are outliers; assign to new dataframe\n",
    "        df_sub01.loc[(df_sub01[i] < otlr_low) | (df_sub01[i] > otlr_high), 'outlier'] = 1\n",
    "        len01 = len(df_sub01)\n",
    "        len02 = len(df_sub01_sub1)\n",
    "        len03 = len(df_sub01_sub2)\n",
    "\n",
    "        fig2, axs = plt.subplots(1, 3, sharey=True, figsize=(12 , 10)) # set figure fram\n",
    "        axs[0].boxplot(df_sub01[i].dropna()) # subplot 1 for full dataset\n",
    "        axs[0].set_title('\\n'.join(wrap(f'Boxplot for {i}: Full Dataset (N = {len01})', 30)))\n",
    "        axs[1].boxplot(df_sub01_sub1[i].dropna()) # subplot 2 for outlier dataset\n",
    "        axs[1].set_title('\\n'.join(wrap(f'Boxplot for {i}: Outliers Subset (n = {len02})', 30)))\n",
    "        axs[2].boxplot(df_sub01_sub2[i].dropna()) # subplot 2 for outlier dataset\n",
    "        axs[2].set_title('\\n'.join(wrap(f'Boxplot for {i}: w/o Outliers Subset (n = {len03})', 30)))\n",
    "        plt.show()\n",
    "\n",
    "        df_sub01.describe()\n",
    "        print(df_sub01[i].describe()) # descriptive stats for CRIM varibale\n",
    "        print('\\n', df_sub01_sub1[i].describe()) # display descriptive stats of data subset\n",
    "        print('\\n', df_sub01_sub2[i].describe()) # display descriptive stats of data subset\n",
    "\n",
    "        print('\\nmean {} = {}'.format(i, round(df_sub01[i].mean(), 4))) # average age for full dataset\n",
    "        print('median {} = {}'.format(i, round(df_sub01[i].median(), 4))) # median age for full dataset\n",
    "\n",
    "        print('\\noutliers mean {} = {}'.format(i, round(df_sub01_sub1[i].mean(), 4))) # average age for outliers\n",
    "        print('outliers median {} = {}'.format(i, round(df_sub01_sub1[i].median(), 4))) # median age for outliers\n",
    "        print('Sub1 Column count = {}'.format(len(df_sub01_sub1.columns))) # alternative way to print only number of columns\n",
    "        print('Sub1 Row count = {}'.format(len(df_sub01_sub1))) # alternative way to print only number of rows\n",
    "\n",
    "        print('\\nw/o outliers mean {} = {}'.format(i, round(df_sub01_sub2[i].mean(), 4))) # average age for outliers\n",
    "        print('w/o outliers median {} = {}'.format(i, round(df_sub01_sub2[i].median(), 4))) # median age for outliers\n",
    "        print('Sub2 Column count = {}'.format(len(df_sub01_sub2.columns))) # alternative way to print only number of columns\n",
    "        print('Sub2 Row count = {}'.format(len(df_sub01_sub2))) # alternative way to print only number of rows\n",
    "    \n",
    "    df_sub01_sub3 = df_sub01.loc[(df_sub01['outlier'] == 0), :]\n",
    "    len04 = len(df_sub01_sub3)\n",
    "    for k, l in var:\n",
    "        fig6 = plt.figure(figsize=(12 , 10)) # set figure fram\n",
    "        plt.boxplot(df_sub01_sub3[k].dropna()) # subplot 1 for full dataset\n",
    "        plt.title('\\n'.join(wrap(f'Boxplot for {k}: Total Subset (n = {len04})', 30)))\n",
    "        plt.show()\n",
    "\n",
    "    return df_sub01_sub3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01676b28-9f1f-40ea-9bb1-9a85a5008b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df01 = box_comp(bank_df01, [('age', 1.5), ('balance', 1.5), ('campaign', 1.5)]) # revise main df to omit records with outliers for age variable\n",
    "bank_df01 = bank_df01.drop('outlier', axis=1)\n",
    "\n",
    "bank_df01_len03 = len(bank_df01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5824f4f0-d455-4013-9ded-fa8170e788bf",
   "metadata": {},
   "source": [
    "##### **Removal  of Outliers**\n",
    "Outliers were removed from `age`, `balance`, and `campaign` based on the function defined above that calculates the IQR for each variable, using a passed-in outlier threshold (e.g., IQR +/- 1 and a half times the IQR), and iterates to assign a flag of 0 or 1 to the total dataset based whether each record is within the outlier range for each applicable variable. This iteration (doing several separate assignments and only one elimination at the end) allows for minimizing how many records are removed from the final dataset, as there may be instances where one record may have outlier values in multiple features. Also, this method ensures that a distribution skew is not introduced through eliminating outliers for one variable, eliminating those records, then proceeding to the next variable--that method would mean that each time the mean may change for each subsequent variable in the (arbitrarily ordered) processing line. The net result is that instead of 7,463 records being eliminated (468 + 4,210 + 2,785), 7,085 were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83861aa8-73ff-4fc5-973f-cd6ed4617b02",
   "metadata": {},
   "source": [
    "### Initial correlation matrix {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262b9a5-5f9b-4adc-9224-d4e073510430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate initial correlation matrix\n",
    "bank_df01_cols_lst02 = bank_df01.columns.values.tolist() # review column names\n",
    "print(bank_df01_cols_lst02)\n",
    "print(len(bank_df01_cols_lst02))\n",
    "bank_df01.loc[:, bank_df01_cols_lst02].corr() # generate correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b8bf9-8497-4629-9e1a-5942bd4458cb",
   "metadata": {},
   "source": [
    "##### **Interpretation of Correlation Matrix**\n",
    "A correlation matrix is displayed above to show the independent relationship between the numerical variables in the dataset. From the correlation matrix, it can be observed that there is not a strong relationship between any them. The strongest observed relationship is between `campaign` and `day` (r = 0.1020), which is still considered to be very weak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04dd54-aab2-4bb9-810c-011a70e8e835",
   "metadata": {},
   "source": [
    "### Scatterplots of numerical variables {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ef7dd-2bb8-4585-ac52-b65372f50fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define function: Produce scatterplots {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529d70c-4db1-4462-8ed4-1a93923edede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatr_vars(df, var_x, var_y):\n",
    "    '''create function to print scatterplots comparing 2 vars'''\n",
    "    y = df[var_y]\n",
    "    x = df[var_x]\n",
    "    x = sm.add_constant(x)\n",
    "    lr_model = sm.OLS(y, x).fit()\n",
    "    '''generate correlation coefficient & statsmodel regression table'''\n",
    "    print('<<<<<-------------------------------------------------------------------->>>>>')\n",
    "    print('r = {}'.format(round(df[var_x].corr(df[var_y]), 4))) # generate correlation coefficient\n",
    "    '''create true regression line'''\n",
    "    x_prime = np.linspace(x[var_x].min(), x[var_x].max(), 100) \n",
    "    x_prime = sm.add_constant(x_prime)\n",
    "    y_hat = lr_model.predict(x_prime)\n",
    "    '''plot x,y & regression line'''\n",
    "    fig = plt.figure(figsize = (20 , 10))\n",
    "    plt.scatter(df[var_x], df[var_y])\n",
    "    plt.xlabel('x axis = {}'.format(var_x))\n",
    "    plt.ylabel('y axis = {}'.format(var_y))\n",
    "    plt.title('Scatterplot Between {} & {}'.format(var_x, var_y))\n",
    "    plt.plot(x_prime[:,1], y_hat, 'red', alpha=.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6540d-08e4-4457-8104-044c1e6d8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scatterplot fx\n",
    "scatr_vars(bank_df01, 'age', 'balance')\n",
    "scatr_vars(bank_df01, 'campaign', 'age')\n",
    "scatr_vars(bank_df01, 'campaign', 'balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f028472-839e-48f8-a34d-8bbbbc5c8cf1",
   "metadata": {},
   "source": [
    "##### **Interpretation of scatterplots**\n",
    "From reviewing the above scatterplot graphs and along with the outputed correlation coefficient, none of the \"natural\" numeric varibales (`age`, `balance`, `campaign`) seem to have a linear relationship with any other. The highest is a very weak positive correlation between `age` and `balance` (*r* = .0868). Note, these plots were done using the cleaned and transformed dataset (*n* = 34,360)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac81d17-b609-406b-b640-551fcda49f21",
   "metadata": {},
   "source": [
    "#### Define function: Discretize categorical feature values {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318432f-b256-452e-b02b-81e658922dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to convert categorical values to discrete numerical\n",
    "col_arr_str = '_arr' # suffix to add to col names for array of cat variables\n",
    "\n",
    "def pcat_list(df, col):\n",
    "    '''define function to convert cat varibales to discrete numeric for correlation'''\n",
    "    cat_var_col = col\n",
    "    cat_var_uniq = df[cat_var_col].unique()\n",
    "    cat_len = len(cat_var_uniq)\n",
    "    int_start = 0\n",
    "    cat_dict = {}\n",
    "    cat_array = np.eye(cat_len, dtype=int)\n",
    "    for i in cat_var_uniq:\n",
    "        cat_dict[i] = cat_array[int_start]\n",
    "        col_name01 = col + '_der'\n",
    "        col_name02 = col + col_arr_str\n",
    "        df.loc[(df[col].isin(cat_dict.keys())), col_name01] = df[col]\n",
    "        int_start += 1\n",
    "        df[col_name02] = df[col_name01].map(cat_dict)\n",
    "    return col_name02\n",
    "\n",
    "\n",
    "def pcat_df(df, col):\n",
    "    '''define function to map cat varibales to discrete numeric'''\n",
    "    cat_var_col = col\n",
    "    cat_var_uniq = df[cat_var_col].unique()\n",
    "    cat_len = len(cat_var_uniq)\n",
    "    int_start = 0\n",
    "    cat_dict = {}\n",
    "    cat_array = np.eye(cat_len, dtype=int)\n",
    "    for i in cat_var_uniq:\n",
    "        cat_dict[i] = int_start\n",
    "        col_name01 = col + '_der02'\n",
    "        col_name02 = col + '_num_map'\n",
    "        df.loc[(df[col].isin(cat_dict.keys())), col_name01] = df[col]\n",
    "        int_start += 1\n",
    "        df[col_name02] = df[col_name01].map(cat_dict)\n",
    "    print(cat_dict)\n",
    "    return df\n",
    "\n",
    "\n",
    "def corr_vars(df, num_list=[], cat_list=[], intract={}):\n",
    "    '''define function to output a correlation matrix for selected num & cat vars'''\n",
    "    df_sub01 = df[num_list]\n",
    "    cat_list_arr = []\n",
    "    col_names01 = []\n",
    "    col_names02 = []\n",
    "    col_names03 = []\n",
    "    merg_list_cont01 = []\n",
    "    merg_list_cont02 = []\n",
    "    merg_list_cont03 = []\n",
    "    col_dict01 = {}\n",
    "    last_col_list01 = []\n",
    "    last_col_list02 = []\n",
    "    '''loop to accumlate cat cols list'''\n",
    "    for i in cat_list: # iterable in basic list of cat vars\n",
    "        cat_list_arr.append(i + col_arr_str) # save col name + suffix to list\n",
    "        col_names02 = list(df[i].unique()) # set list with unique values from cat vars cols\n",
    "        col_names04 = [] # initalize list\n",
    "        '''loop to add prefix to cat vals'''\n",
    "        for m in col_names02: # iterabale in list of unique cat vals\n",
    "            cat_full_name = str(i) + '_' + str(m)\n",
    "            col_names04.append(cat_full_name)\n",
    "        for b in intract:\n",
    "            d_val = intract[b]\n",
    "            for z in d_val:\n",
    "                col_names05 = [] # initalize list\n",
    "                if i == z:\n",
    "                    for u in col_names04:\n",
    "                        col_names05.append(str(b) + '_' + str(u) + '_in')\n",
    "                    merg_list_cont01.extend(col_names04)\n",
    "                else:\n",
    "                    pass\n",
    "                merg_list_cont02.extend(col_names05)\n",
    "                last_col_list02.extend(col_names05[-1:]) # keep track of cols at the end after each pass\n",
    "                merged_list = [(merg_list_cont02[i], merg_list_cont01[i]) for i in range(0, len(merg_list_cont02))]\n",
    "                col_dict01[b] = merged_list\n",
    "        col_names03.append(col_names04) # save list of col + cat vals to list\n",
    "        col_names01.append(col_names02)\n",
    "    int_start = 0\n",
    "    '''loop to extend cat vars to new cols'''\n",
    "    for i in cat_list_arr: # iterable in new cols list\n",
    "        df02 = df[i].apply(pd.Series) # extend the vals to new cols\n",
    "        num_list.extend(col_names03[int_start])\n",
    "        df_sub01 = pd.concat([df_sub01, df02], axis=1) # splice new ext cols to orig cols\n",
    "        df_sub01.columns = num_list \n",
    "        last_col_list01.extend(num_list[-1:]) # keep track of cols at the end after each pass\n",
    "        int_start += 1\n",
    "    '''add new cols for vars w/ interactions'''\n",
    "    for s in col_dict01:\n",
    "        d_val02 = col_dict01[s]\n",
    "        for t, w in d_val02:\n",
    "            df_sub01.loc[:, t] = df_sub01[s] * df_sub01[w]\n",
    "    df_sub02 = df_sub01.drop(last_col_list01, axis=1) # drop based on c-1 cats\n",
    "    df_sub02 = df_sub02.drop(last_col_list02, axis=1) # drop based on c-1 cats\n",
    "    col_names = list(df_sub01.columns)\n",
    "    print(f'\\nColumn Names:\\n{col_names}')\n",
    "\n",
    "    return df_sub01.loc[:, col_names].corr(), df_sub01, df_sub02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2bbc8-4e67-4f49-9452-d34b2643f93b",
   "metadata": {},
   "source": [
    "### Key variable definitions {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1acdd-6231-43e6-a32c-3ebc9c7163b4",
   "metadata": {},
   "source": [
    "#### Variables for predicting `deposit` values {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9cba5-0025-4c1e-be1c-3fc4b8b4215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variable lists for functions & analysis\n",
    "y_cor_vars_m2 = 'deposit'\n",
    "\n",
    "num_vars_process_m2_01 = [y_cor_vars_m2, 'age', 'balance', 'campaign', 'previous_contact'] # dependent variable & core numerical variables\n",
    "\n",
    "cat_vars_process_m2_01 = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'day', 'month'] # relevant caterigal varaibles for df02\n",
    "cat_vars_process_m2_02 = [y_cor_vars_m2, 'job', 'marital', 'education', 'default', 'housing', 'loan', 'day', 'month'] # relevant caterigal varaibles for df06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26371a-3087-401f-9c0f-3385d49d7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scatterplot fx\n",
    "scatr_vars(bank_df01, 'age', 'balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2fc10a-c954-417b-bd86-d2cafdd469e2",
   "metadata": {},
   "source": [
    "#### Subset Descriptive statistics {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd2325-8b37-4e0b-b493-101faa19299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df01.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049560d-fb2d-4350-b92a-aa92bc846d66",
   "metadata": {},
   "source": [
    "### Dataset branching {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d3e868-0643-43a5-9a7b-c03be87c9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df22 = bank_df01.copy().dropna()\n",
    "\n",
    "bank_df22_len01 = len(bank_df22)\n",
    "\n",
    "print(f'Original N = {bank_df01_len01}\\nNew n = {bank_df22_len01}\\n% Loss = {round((1-(bank_df22_len01/bank_df01_len01))*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6f2a2-b57c-40f7-a4ba-5a9a28b8ef3e",
   "metadata": {},
   "source": [
    "##### **Final explanation of record cleaning & trimming**\n",
    "The final percent loss of records was 24%, reducing the count from 45,211 to 34,360. Considering the large N that was started with, the fact that three variables had missing values, most of the numerical variables had large amounts of data points +/- 1.5 time the IQR, and the remaining count is still large, it has been decided that the percent loss is acceptable for the analyses to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d560c1-5ea7-4751-9818-b72800a5fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for consolidate correlation of cat vars\n",
    "for i in cat_vars_process_m2_02:\n",
    "    bank_df26 = pcat_df(bank_df22, i)\n",
    "\n",
    "bank_df28 = bank_df26.copy().dropna()\n",
    "\n",
    "print(bank_df26.head(10))\n",
    "print(bank_df28.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174230d8-58fe-4a05-8e20-567be0ce876d",
   "metadata": {},
   "source": [
    "### Discretize key categorical features {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8929f14",
   "metadata": {},
   "source": [
    "#### Run correlation & regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9337235-e4d5-4d00-811f-915cd10a6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new list\n",
    "new_col_list02 = []\n",
    "\n",
    "# Loop using function to populate new col list\n",
    "for i in cat_vars_process_m2_01:\n",
    "    nm02 = pcat_list(bank_df22, i)\n",
    "    new_col_list02.append(nm02)\n",
    "\n",
    "interact_dict02 = {'balance': ['job', 'education', 'marital'], 'age': ['job', 'education']}\n",
    "full_corr01_m2, bank_df22, bank_df23  = corr_vars(bank_df22, num_vars_process_m2_01, cat_vars_process_m2_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04c78c-bc8d-4fad-82e7-ed86141a85e6",
   "metadata": {},
   "source": [
    "### Updated correlation matrices {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de75f3-3a27-4429-9e6d-bcfa80da4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate referential correlation matrix w/ full cat mapping (not c-1)\n",
    "bank_df26_cols_lst = bank_df26.columns.values.tolist() # review column names\n",
    "print(bank_df26_cols_lst)\n",
    "print(len(bank_df26_cols_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ae67b-95f2-4542-abc9-596c08e6c5da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_corr01_m2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff6b3b",
   "metadata": {},
   "source": [
    "##### **Interpretation of Overall Correlation Matrix**\n",
    "The Correlation matrix above was outputed to show the relationship between all of the variables in the dataset, after the imputation and alteration of the categorical variables and the missing values. Due to the discretized categorical variables, the correlation matrix loses its ability to inform on the relationship between two predictor variables. So, while the correlation table still provides a useful measure of the relationship between numerical variables (i.e. `age`, `balance`, `campaign`, ...) it not longer provides a useful measurement for the relationship betweent he discretized categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4bae3-a9d8-4e36-8aa1-c7e8f12a954c",
   "metadata": {},
   "source": [
    "## 3. Data Analytics {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53be5e",
   "metadata": {},
   "source": [
    "#### **Data Legend:** \\\n",
    "bank_df01--> original bank_marketing.csv imported as a pandas df \\\n",
    "bank_df28--> discretized variables \\\n",
    "bank_df22--> full discretized dataset with all dummy variables \\\n",
    "bank_df23--> dummies; c-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ec529",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df42 = bank_df22.copy()\n",
    "bank_df42 = pcat_df(bank_df42, 'deposit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abcf12",
   "metadata": {},
   "source": [
    "##### **R & Python integration**\n",
    "To get the bank dataset compatible with R, the `deposit` variable outputs have been changed from categorical to binary, with deposit \"no\" as 0 and deposit \"yes\" as 1, using the pcat_df function. A new dataframe has been created called bank_df_r from the bank_df42 dataframe. Then, the bank_df_r dataset can be read into R using the RPY2 package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6d77b-0af4-4dfa-aaaa-03928afa4618",
   "metadata": {},
   "source": [
    "### Develop R Logistic Regression Models {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1151b6-b131-432c-96a4-9ed1ad51ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df_r = bank_df42\n",
    "print(bank_df_r.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f059b-0645-4cf0-a2d1-003bac1d08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ratio of yes/no in deposit var\n",
    "yes_len = len(bank_df42.loc[(bank_df42['deposit'] == 'yes'), :])\n",
    "no_len = len(bank_df42.loc[(bank_df42['deposit'] == 'no'), :])\n",
    "full_len = len(bank_df42)\n",
    "print(f'Subset len for \"yes\" = {yes_len}')\n",
    "print(f'Subset len for \"no\" = {no_len}')\n",
    "print(f'Subset len for full dataset = {full_len}')\n",
    "print(f'yes % = {round((yes_len/full_len)*100, 4)}%')\n",
    "print(f'no % = {round((no_len/full_len)*100, 4)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9516f-2e08-4735-a7cb-f04315eb587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review value count of dependent var\n",
    "print(len(bank_df42.loc[(bank_df42[y_cor_vars_m2] == 'yes'), :]))\n",
    "print(len(bank_df42.loc[(bank_df42[y_cor_vars_m2] != 'yes'), :]))\n",
    "\n",
    "# Subset default set\n",
    "bank_df42c = bank_df42.loc[(bank_df42[y_cor_vars_m2] == 'yes'), :]\n",
    "bank_df42d = bank_df42.loc[(bank_df42[y_cor_vars_m2] != 'yes'), :]\n",
    "frac_target_42 = .4\n",
    "n01_m1df42_sample = int((len(bank_df42c) / frac_target_42)) - len(bank_df42c)\n",
    "bank_df42e = bank_df42d.sample(n = n01_m1df42_sample)\n",
    "bank_df42f = pd.concat([bank_df42c, bank_df42e])\n",
    "print(f'\\nbank_df42f\\nlen = {len(bank_df42f)}\\n\\ndf:\\n{bank_df42f.head(5)}')\n",
    "\n",
    "bank_df_r2 = bank_df42f\n",
    "print(bank_df_r2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9aaa30-dbab-4832-84e6-b3731cf0b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = robjects.conversion.py2rpy(bank_df_r)\n",
    "r_df2 = robjects.conversion.py2rpy(bank_df_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bea94-2b73-401b-a847-dcdb816e418b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R -i r_df\n",
    "%R head(r_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998ed01-20d7-4dee-88eb-6341e30970ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R -i r_df2\n",
    "%R (head(r_df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b46d51",
   "metadata": {},
   "source": [
    "##### **Using RPY2 magic function**\n",
    "After creating the bank_df_r dataframe, the robjects.conversion command was used to make the python bank_df_r dataframe into an R compatible dataframe, now called r_df. After the conversion, the dataframe can now be read into R using cell magic (i.e., %R--denoting R codeblock). The r_df dataframe has been printed in R to double check that the file has been read in correctly, with all the variables and outputs as a table, not an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf024d82-6b7c-47f4-bbe5-188dd40f78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R hist(r_df$age)\n",
    "%R hist(r_df$balance)\n",
    "%R hist(r_df$campaign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e4baf",
   "metadata": {},
   "source": [
    "##### **Interpretation of histograms for numeric variables (`age`, `balance`, `campaign`)**\n",
    "The histogram for age displays a slight right skew, so the dataset has a slightly larger number of younger individuals than older individuals. The histogram for balance displays a strong right skew, so the dataset has a much larger number of lower balances than higher balances. The histogram for campaign displays a right skew as well, so most of the campaign values cluster to the left. This means that of the individuals in the dataset, more of them were contacted less frequently during the campaign for the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R names(r_df)[names(r_df)==\"job_blue-collar\"] <- \"job_blue_collar\"\n",
    "%R names(r_df)[names(r_df)==\"job_self-employed\"] <- \"job_self_employed\"\n",
    "%R head(r_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b4f6c-3564-41ec-ada7-a157a304bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R sample1 <- floor(0.70 * nrow(r_df))\n",
    "%R set.seed(1234)\n",
    "%R train_ind <- sample(seq_len(nrow(r_df)), size=sample1)\n",
    "%R train_r_df <- r_df[train_ind, ]\n",
    "%R test_r_df <- r_df[-train_ind, ]\n",
    "\n",
    "%R sample2 <- floor(0.70 * nrow(r_df2))\n",
    "%R set.seed(1234)\n",
    "%R train_ind2 <- sample(seq_len(nrow(r_df2)), size=sample2)\n",
    "%R train_r_df2 <- r_df2[train_ind2, ]\n",
    "%R test_r_df2 <- r_df2[-train_ind2, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffcc34-85f6-4f73-9b1e-8e371556cea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R train_r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R test_r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7745786",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R test_df_colum_nums <- colnames(test_r_df)\n",
    "%R print(test_df_colum_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8e89f",
   "metadata": {},
   "source": [
    "##### **Creating Train & Test Subsets**\n",
    "First, the column names for job_blue-collar and job_self-employed have been changed to job_blue_collar and job_self_employed, using the tidyverse package in R. This was done to create uniformity in the names of the columns in the dataset, important for modeling the data later. Second, training and testing subsets were created from the r_df dataframe, using the caTools package. The r_df data was split 70/30 for the train_r_df (24,052 rows) and test_r_df (10,308 rows). The last step taken before modeling the deposit variable using logistic regressions was to print the test_df_r column names and corresponding column number. This step was taken to have reference to the columns used in the logistic regression models below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0bea5",
   "metadata": {},
   "source": [
    "#### Model 1: Simple Logistic Regression (deposit ~ previous_contact) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c26af6-fcd9-4fc6-8d1b-a2bcc51f9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R log_r <- glm(deposit_num_map ~ previous_contact, data=train_r_df, family=binomial)\n",
    "%R print(log_r)\n",
    "%R log_r_summary <- summary(log_r)\n",
    "%R print(log_r_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe239d5",
   "metadata": {},
   "source": [
    "#### Model 1: Receiver Operator Curve & Area Under the Curve {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec12ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R p <- predict(log_r, newdata=subset(test_r_df, select=c(5)), type=\"response\")\n",
    "%R pr <- prediction(p, test_r_df$deposit_num_map)\n",
    "%R prf <- performance(pr, measure= \"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf)\n",
    "%R auc <- performance(pr, measure=\"auc\")\n",
    "%R auc <- auc@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548c26f",
   "metadata": {},
   "source": [
    "#### Model 1 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R log_r_test <- predict(log_r, newdata=subset(test_r_df, select=c(5)), type=\"response\")\n",
    "%R log_r_test <- ifelse(log_r_test>0.5,1,0)\n",
    "%R misclasificerror <- mean(log_r_test!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef972a26",
   "metadata": {},
   "source": [
    "##### **Model 1 Interpretation**\n",
    "Model 1 is a simple logistic regression where the R application glm method is used to determine deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from `previous_contact` as the independent variables in a training subset (train_r_df) of the full trimmed and cleanded dataset (*N* = 34,360). The intercept was calculated to be -2.264 and the regression coefficient for `previous_contact` to be 1.043, with a statistically significant *p*-value <.001. This means that as the number of previous contacts increases, there is a positive increase in the log odds (and by extension probability) of the client subscribing to a term deposit. Model 1 indicates that `previous_contact` is significant in determining the deposit status. The receiver operating curve (ROC) was then plotted to calculate the area under the curve (AUC). The ROC curve plots the true positive rate against the false positive rate, with AUC values closer to 1 indicating a good predictive model. The AUC for model 1 is equal to 0.6131, so the area under the ROC covers about 61% of the rectangle, indicating that model 1 does not have great predictive ability. The accuracy for the model is also reported to measure how well the model developed using the training data performed in predicting values within the test_r_df subset. The accuracy for model 1 is equal to 0.8786, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 1's ability to predict deposit is not great, and this is most likely due to the fact that only predictor variable is included but there is more than one factor affecting if the client decides to subscribe to a term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60179e9",
   "metadata": {},
   "source": [
    "#### Model 2: Simple Logistic Regression (deposit ~ campaign) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f706218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R log_r_2 <- glm(deposit_num_map ~ campaign, data=train_r_df, family=binomial)\n",
    "%R print(log_r_2)\n",
    "\n",
    "%R log_r_2_summary <- summary(log_r_2)\n",
    "%R print(log_r_2_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca791660",
   "metadata": {},
   "source": [
    "#### Model 2: Receiver Operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a87e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R log_r_2_test <- predict(log_r_2, newdata=subset(test_r_df, select=c(4)), type=\"response\")\n",
    "%R log_r_2_test <- ifelse(log_r_2_test>0.5,1,0)\n",
    "\n",
    "%R p_log_r_2 <- predict(log_r_2, newdata=subset(test_r_df, select=c(4)), type=\"response\")\n",
    "%R pr_log_r_2 <- prediction(p_log_r_2, test_r_df$deposit_num_map)\n",
    "%R prf_log_r_2 <- performance(pr_log_r_2, measure= \"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_log_r_2)\n",
    "\n",
    "%R auc_log_r_2 <- performance(pr_log_r_2, measure=\"auc\")\n",
    "%R auc_log_r_2 <- auc_log_r_2@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c591d41",
   "metadata": {},
   "source": [
    "#### Model 2 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e960c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R log_r_2_test <- predict(log_r_2, newdata=subset(test_r_df, select=c(4)), type=\"response\")\n",
    "%R log_r_2_test <- ifelse(log_r_2_test>0.5,1,0)\n",
    "%R misclasificerror_2 <- mean(log_r_2_test!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d90b5",
   "metadata": {},
   "source": [
    "##### **Model 2 Interpretation**\n",
    "Model 2 is a simple logistic regression where the R application glm method is used to determine deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from `campaign` as the independent variable in a training subset (train_r_df) of the full trimmed and cleaned dataset (*N* = 34,360). The intercept was calculated to be -1.66857  and the regression coefficient for `campaign` to be -0.15859, with a statistically significant *p*-value <.001. This means that as the number of contacts performed during the campaign increases, there is a decrease in the log odds (and by extension probability) of the client subscribing to a term deposit. Model 2 indicates that `campaign` is significant in determining the deposit status. The ROC was then plotted to calculate the AUC. The AUC for model 2 is equal to 0.5645, so the area under the ROC covers about 56% of the rectangle, indicating that model 2 has a poor predictive ability.  The accuracy of model 2 is equal to 0.8786, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 2's ability to predict deposit is poor, and this is most likely due to the fact that only one predictor variable is included in the regression equation, similar to model 1. This second simple logistic regression was performed to better understand which predictor variables have large affects on deposit status, by itself. This information will later be used in the multiple logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbb236",
   "metadata": {},
   "source": [
    "#### Model 3: Simple Logistic Regression (deposit ~ balance) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd61716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R log_r_3 <- glm(deposit_num_map ~ balance , data=train_r_df, family=binomial)\n",
    "%R print(log_r_3)\n",
    "\n",
    "%R log_r_3_summary <- summary(log_r_3)\n",
    "%R print(log_r_3_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea99007d",
   "metadata": {},
   "source": [
    "#### Model 3: Receiver Operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77a681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R log_r_3_test <- predict(log_r_3, newdata=subset(test_r_df, select=c(3)), type=\"response\")\n",
    "%R log_r_3_test <- ifelse(log_r_3_test>0.5,1,0)\n",
    "\n",
    "%R p_log_r_3 <- predict(log_r_3, newdata=subset(test_r_df, select=c(3)), type=\"response\")\n",
    "%R pr_log_r_3 <- prediction(p_log_r_3, test_r_df$deposit_num_map)\n",
    "%R prf_log_r_3 <- performance(pr_log_r_3, measure= \"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_log_r_3)\n",
    "\n",
    "%R auc_log_r_3 <- performance(pr_log_r_3, measure=\"auc\")\n",
    "%R auc_log_r_3 <- auc_log_r_3@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5100519",
   "metadata": {},
   "source": [
    "#### Model 3 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631da46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R log_r_3_test <- predict(log_r_3, newdata=subset(test_r_df, select=c(3)), type=\"response\")\n",
    "%R log_r_3_test <- ifelse(log_r_3_test>0.5,1,0)\n",
    "%R misclasificerror_3 <- mean(log_r_3_test!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ff57d",
   "metadata": {},
   "source": [
    "##### **Model 3 Interpretation**\n",
    "Model 3 is another simple logistic regression where the R application glm method is used to determine deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from `balance` as the independent variable in a training subset (train_r_df) of the full trimmed and cleaned dataset (*N* = 34,360). The intercept was calculated to be -2.20501 and the regression coefficient for `balance` to be 0.00025, with statistically significant *p*-value <.001. This means that as the average yearly balance in Euros increases, there is a slight increase in the log odds (and by extension probability) of the client subscribing to a term deposit. Model 3 indicates that `balance` is significant in determining the deposit status. The ROC was then plotted to calculate the AUC. The AUC for model 3 is equal to 0.5701, so the area under the ROC covers about 57% of the rectangle, indicating that model 3 has a poor predictive ability. The accuracy of model 3 is equal to 0.8786, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 3's ability to predict deposit is poor, and this is again most likely due to the fact that only one predictor variable is included in the regression equation, like model 1 and model 2. Now that simple logsitic regressions have been modeled to see which predictor variables have larger individual impacts on the deposit status, more complex multiple logistic regressions can be modeled, illustrating a more realistic relationship between deposit status and multiple predictor variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2d772",
   "metadata": {},
   "source": [
    "#### Model 4: Multiple Logistic Regression (deposit ~ age+72 other variables....) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e741e0-739d-4f20-b362-3f2062e3e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R initial_logreg_model <- glm(deposit_num_map ~ age+balance+previous_contact+campaign+job_management+job_technician\\\n",
    "                               +job_entrepreneur+job_blue_collar+job_student+job_retired+job_admin.\\\n",
    "                               +job_services+job_self_employed\\\n",
    "                               +job_unemployed+job_housemaid+marital_married+marital_single\\\n",
    "                               +marital_divorced+education_tertiary+education_secondary\\\n",
    "                               +education_primary+education_unknown+default_yes+default_no\\\n",
    "                               +housing_yes+housing_no+loan_no+loan_yes+day_1+day_2+day_3\\\n",
    "                               +day_4+day_5+day_6+day_7+day_8+day_9+day_10+day_11\\\n",
    "                               +day_12+day_13+day_14+day_15+day_16+day_17+day_18\\\n",
    "                               +day_19+day_20+day_21+day_22+day_23+day_24+day_25\\\n",
    "                               +day_26+day_27+day_28+day_29+day_30+day_31+month_may\\\n",
    "                               +month_jun+month_jul+month_aug+month_oct\\\n",
    "                               +month_nov+month_dec+month_jan+month_feb\\\n",
    "                               +month_mar+month_apr+month_sep, data=train_r_df, family=binomial)\n",
    "%R print(initial_logreg_model)\n",
    "\n",
    "%R initial_logreg_model_summary <- summary(initial_logreg_model)\n",
    "%R print(initial_logreg_model_summary)\n",
    "\n",
    "%R ld.vars <- attributes(alias(initial_logreg_model)$Complete)$dimnames[[1]]\n",
    "%R print(ld.vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73916d62",
   "metadata": {},
   "source": [
    "#### Model 4: Receiver Operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R p_initial_logreg_model <- predict(initial_logreg_model, newdata=subset(test_r_df, select=c(2,3,4,5,6,7,8,9,10,11\\\n",
    "                                                                                              ,12,13,14,15,16,17,18\\\n",
    "                                                                                              ,19,20,21,22,23,24,25\\\n",
    "                                                                                              ,26,27,28,29,30,31,32\\\n",
    "                                                                                              ,33,34,35,36,37,38,39\\\n",
    "                                                                                              ,40,41,42,43,44,45,46\\\n",
    "                                                                                              ,47,48,49,50,51,52,53\\\n",
    "                                                                                              ,54,55,56,57,58,59,60\\\n",
    "                                                                                              ,61,62,63,64,65,66,67\\\n",
    "                                                                                              ,68,69,70,71,72)), type=\"response\")\n",
    "%R pr_initial_logreg_model <- prediction (p_initial_logreg_model, test_r_df$deposit_num_map)\n",
    "%R prf_initial_logreg_model <- performance(pr_initial_logreg_model, measure=\"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_initial_logreg_model)\n",
    "\n",
    "%R auc_initial <- performance(pr_initial_logreg_model, measure=\"auc\")\n",
    "%R auc_initial <- auc_initial@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ac2d6",
   "metadata": {},
   "source": [
    "#### Model 4 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211874cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R train_r_df <- r_df[train_ind, ]\n",
    "%R test_r_df <- r_df[-train_ind, ]\n",
    "\n",
    "%R initial_logreg_model_test_4 <- predict(initial_logreg_model, newdata=subset(test_r_df, select=c(2,3,4,5,6,7,8,9,10\\\n",
    "                                                                                                   ,11,12,13,14,15,16\\\n",
    "                                                                                                   ,17,18,19,20,21,22\\\n",
    "                                                                                                   ,23,24,25,26,27,28\\\n",
    "                                                                                                   ,29,30,31,32,33,34\\\n",
    "                                                                                                   ,35,36,37,38,39,40\\\n",
    "                                                                                                   ,41,42,43,44,45,46\\\n",
    "                                                                                                   ,47,48,49,50,51,52\\\n",
    "                                                                                                   ,53,54,55,56,57,58\\\n",
    "                                                                                                   ,59,60,61,62,63,64\\\n",
    "                                                                                                   ,65,66,67,68,69,70\\\n",
    "                                                                                                   ,71,72)), type=\"response\")\n",
    "%R initial_logreg_model_test_4 <- ifelse(initial_logreg_model_test_4>0.5,1,0)\n",
    "\n",
    "%R misclasificerror_4 <- mean(initial_logreg_model_test_4!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81642b2",
   "metadata": {},
   "source": [
    "##### **Model 4 Interpretation**\n",
    "Model 4 presents the first multiple logistic regression where the R application glm method is used to determine the deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from all 73 predictors as the independent variables in a training subset (train_r_df) of the full trimmed and cleaned dataset (*N* = 34,360). The intercept was calculated to be -1.785e+00. The regression coefficients for the 73 independent variables can be found above along with their *p*-values and significance levels. Many of the independent variables have a significant *p*-value, indicating that a multiple logistic regression is more appropriate for this data than a simple logistic regression. The ROC was then plotted to calcuate the AUC. The AUC for model 4 is equal to 0.7458, so the area under the ROC covers about 75% of the rectangle, indicating that model 4 has an moderate predictive ability. The accuracy of model 4 is equal to 0.8815, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 4's ability to predict deposit is moderate, most likely due to the fact that there are linearly dependent variables being used, affecting the overall affect on deposit status. The attributes function was used to output the linearly dependent variables (i.e., `job_housemaid`, `marital_divorced`, `education_unknown`, `default_no`, `housing_no`, `loan_yes`, `day_31`, and `month_sep`) illustrated by the \"NA\" outputs in the model 4 summary table. Given that these variables were found to be linearly dependent, they have been removed for the next model (i.e., model 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645e549",
   "metadata": {},
   "source": [
    "#### Model 5: Trimmed Multiple Logistic Regression (deposit ~ age+64 other variables.... {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R logreg_model <- glm(deposit_num_map ~ age+balance+previous_contact+campaign+job_management\\\n",
    "                       +job_technician+job_entrepreneur+job_blue_collar+job_student\\\n",
    "                       +job_retired+job_admin.+job_services+job_self_employed\\\n",
    "                       +job_unemployed+marital_married+marital_single+education_tertiary\\\n",
    "                       +education_secondary+education_primary+default_yes+housing_yes\\\n",
    "                       +loan_no+day_1+day_2+day_3+day_4+day_5+day_6+day_7+day_8+day_9\\\n",
    "                       +day_10+day_11+day_12+day_13+day_14+day_15+day_16+day_17+day_18\\\n",
    "                       +day_19+day_20+day_21+day_22+day_23+day_24+day_25+day_26+day_27\\\n",
    "                       +day_28+day_29+day_30+month_may+month_jun+month_jul+month_aug\\\n",
    "                       +month_oct+month_nov+month_dec+month_jan+month_feb+month_mar\\\n",
    "                       +month_apr, data=train_r_df, family=binomial)\n",
    "\n",
    "%R logreg_model_summary <- summary(logreg_model)\n",
    "%R print(logreg_model_summary)\n",
    "\n",
    "%R vif(logreg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa57a8d8",
   "metadata": {},
   "source": [
    "#### Model 5: Receiver Operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee3022-576b-461c-aa6d-65c6a886f419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R p_logreg_model <- predict(logreg_model, newdata=subset(test_r_df, select=c(2,3,4,5,6,7,8,9\\\n",
    "                                                                              ,10,11,12,13,14\\\n",
    "                                                                              ,15,17,18,20,21\\\n",
    "                                                                              ,22,25,26,28,30\\\n",
    "                                                                              ,31,32,33,34,35\\\n",
    "                                                                              ,36,37,38,39,40\\\n",
    "                                                                              ,41,42,43,44,45\\\n",
    "                                                                              ,46,47,48,49,50\\\n",
    "                                                                              ,51,52,53,54,55\\\n",
    "                                                                              ,56,57,58,59,61\\\n",
    "                                                                              ,62,63,64,65,66\\\n",
    "                                                                              ,67,68,69,70,71)), type=\"response\")\n",
    "%R pr_logreg_model <- prediction (p_logreg_model, test_r_df$deposit_num_map)\n",
    "%R prf_logreg_model <- performance(pr_logreg_model, measure=\"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_logreg_model)\n",
    "\n",
    "%R auc_logreg <- performance(pr_logreg_model, measure=\"auc\")\n",
    "%R auc_logreg <- auc_logreg@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536de393",
   "metadata": {},
   "source": [
    "#### Model 5 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f317b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R trim_logreg_model_test_5 <- predict(logreg_model, newdata=subset(test_r_df, select=c(2,3,4,5,6,7,8,9\\\n",
    "                                                                                        ,10,11,12,13,14\\\n",
    "                                                                                        ,15,17,18,20,21\\\n",
    "                                                                                        ,22,25,26,28,30\\\n",
    "                                                                                        ,31,32,33,34,35\\\n",
    "                                                                                        ,36,37,38,39,40\\\n",
    "                                                                                        ,41,42,43,44,45\\\n",
    "                                                                                        ,46,47,48,49,50\\\n",
    "                                                                                        ,51,52,53,54,55\\\n",
    "                                                                                        ,56,57,58,59,61\\\n",
    "                                                                                        ,62,63,64,65,66\\\n",
    "                                                                                        ,67,68,69,70,71))\\\n",
    "                                       , type=\"response\")\n",
    "%R trim_logreg_model_test_5 <- ifelse(trim_logreg_model_test_5>0.5,1,0)\n",
    "%R misclasificerror_5 <- mean(trim_logreg_model_test_5!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583e8ab",
   "metadata": {},
   "source": [
    "##### **Model 5 Interpretation**\n",
    "Model 5 presents a trimmed multiple logistic regression where the R application glm method is used to determine the deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from 65 predictors as the independent variables in a training subset (train_r_df) of the full trimmed and cleaned dataset (*N* = 34,360). The variables that exhibited perfect linear dependence have been removed for model 5. The intercept was calculated to be -1.785e+00. The regression coefficients for the 65 independent variables can be found above along with their *p*-values and significance levels. Many of the independent variables have a significant *p*-value, indicating that a multiple logistic regression is still appropriate. \\\n",
    "The VIF's for the independent variables were also calculated to show the linear dependency of each variable in model 5. The ROC was then plotted to calcuate the AUC. The AUC for model 5 is equal to 0.7458, so the area under the ROC covers about 75% of the rectangle, indicating that model 5 has a moderate predictive ability. The accuracy of model 5 is equal to 0.8815, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 5's ability to predict deposit is moderate, most likely due to the fact that there are still variables being used that exhibit some degree of linear dependence, affecting the overall affect on deposit status. To mitigate this issue in model 5, model 6 removes the variables with a calculated VIF>2.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0adce8",
   "metadata": {},
   "source": [
    "#### Model 6: Trimmed Multiple Logistic Regression \n",
    "(default~age+balance+campaign+previous_contact+job_entrepreneuer+default_yes+housing_yes+loan_no+month_dec+month_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50618d-b9ee-46e5-918c-28da3a5f6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluing variables with a vif>2.5#\n",
    "%R trim_logreg_model <- glm(deposit_num_map ~ age + balance + campaign + previous_contact\\\n",
    "                            + job_entrepreneur + default_yes + housing_yes + loan_no\\\n",
    "                            + month_dec + month_mar, data=train_r_df, family=binomial())\n",
    "%R print(trim_logreg_model)\n",
    "\n",
    "%R trim_logreg_model_summary <- summary(trim_logreg_model)\n",
    "%R print(trim_logreg_model_summary)\n",
    "\n",
    "%R vif(trim_logreg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfad362",
   "metadata": {},
   "source": [
    "#### Model 6: Receiver  operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R p_trim_logreg_model <- predict(trim_logreg_model, newdata=subset(test_r_df, select=c(2,3,4,5,8,25,26\\\n",
    "                                                                                        ,28,67,70)), type=\"response\")\n",
    "%R pr_trim_logreg_model <- prediction (p_trim_logreg_model, test_r_df$deposit_num_map)\n",
    "%R prf_trim_logreg_model <- performance(pr_trim_logreg_model, measure=\"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_trim_logreg_model)\n",
    "\n",
    "%R auc_trim_6 <- performance(pr_trim_logreg_model, measure=\"auc\")\n",
    "%R auc_trim_6 <- auc_trim_6@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3922b",
   "metadata": {},
   "source": [
    "#### Model 6 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887fd480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R trim_logreg_model_test_6 <- predict(trim_logreg_model, newdata=subset(test_r_df, select=c(2,3,4,5,8,25,26,28\\\n",
    "                                                                                             ,67,70)), type=\"response\")\n",
    "%R trim_logreg_model_test_6 <- ifelse(trim_logreg_model_test_6>0.5,1,0)\n",
    "%R misclasificerror_6 <- mean(trim_logreg_model_test_6!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6726ba",
   "metadata": {},
   "source": [
    "##### **Model 6 Interpretation**\n",
    "Model 6 presents another trimmed multiple logistic regression where the R application glm method is used to determine the deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from `age`, `balance`, `campaign`, `previous_contact`, `job_entrepreneur`, `default_yes`, `housing_yes`, `loan_no`, `month_dec`, and `month_mar` as the independent variables in a training subset (train_r_df) of the full trimmed and cleaned dataset (*N* = 34,360). The variables that exhibited a VIF>2.5 have been removed for model 6. The intercept was calculated to be -1.810e+00. \\\n",
    "The regression coefficient for `age` is -0.00957 with a statistically significant *p*-value <.001. This means that as age increases, there is a slight decrease in the log odds (and by extension probability) of the client subscribing to a term deposit. Model 6 indicates that `age` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `balance` is 0.00019 with a statistically significant *p*-value <.001. This means that as average yearly balance in Euros increases, there is a slight increase in the log odds of the client subscribing to a term deposit. Model 6 indicates that `balance` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `campaign` is -0.12680 with a statistically significant *p*-value <.001. This means that as campaign increases, there is a decrease in the log odds of the client subscribing to a term deposit. Model 6 indicates that `campaign` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `previous_contact` is 1.0620 with a statistically significant *p*-value <.001. This means that based on whether there was previous contact there is a moderate increase in the log odds of the client subscribing to a term deposit. Model 6 indicates that `previous_contact` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `job_entrepreneur` is -0.29270 with a statistically significant *p*-value <.05. This means that when a person's job is entrepreneur, there is a slight decrease in the log odds of the client subscribing to a term deposit. Model 6 indicates that `job_entrepreneur` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `default_yes` is -0.41920 with a *p*-value of 0.1356. This means that if you default, there is a increase in the log odds of the client subscribing to a term deposit. Model 6 indicates that `default_yes` is not significant in determining the deposit status. \\\n",
    "The regression coefficient for `housing_yes` is -0.99900 with a statistically significant *p*-value <.001. This means that people with a housing loan, decrease the log odds of the client subscribing to a term deposit. Model 6 indicates that `housing_yes` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `loan_no` is 0.53270 with a statistically significant *p*-value <.001. This means that people without a personal loan, increase the log odds of the client subscribing to a term deposit. Model 6 indicates that `loan_no` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `month_dec` is 0.92550 with a statistically significant *p*-value <.001. This means that people who were last contacted about the deposit in December, increase the log odds of the client subscribing to a term deposit. Model 6 indicates that `month_dec` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `month_mar` is 1.5940 with a statistically significant *p*-value <.001. This means that people who were last contacted about the deposit in March, increase the log odds of the client subscribing to a term deposit. Model 6 indicates that `month_mar` is significant in determining the deposit status. \\\n",
    "The ROC was then plotted to calcuate the AUC. The AUC for model 6 is equal to 0.7145, so the area under the ROC covers about 71% of the rectangle, indicating that model 6 has a moderate predictive ability. The accuracy of model 6 is equal to 0.8805, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 6's ability to predict deposit is moderate, most likely due to including the `default_yes` variable. Since this variable was not significant, it will be removed for model 7, to more accurately depict a logistic model for deposit status. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d05905",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Model 7: Trimmed Multiple Regression \n",
    "(deposit~age+balance+camapgin+previous-contact+job_entrepreneuer+housing_yes+loan_no+month_dec+month_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model!!\n",
    "%R trim_logreg_model_7 <- glm(deposit_num_map ~ age +balance + campaign + previous_contact\\\n",
    "                              + job_entrepreneur + housing_yes + loan_no + month_dec\\\n",
    "                              + month_mar, data=train_r_df, family=binomial())\n",
    "%R print(trim_logreg_model_7)\n",
    "\n",
    "%R trim_logreg_model_7_summary <- summary(trim_logreg_model_7)\n",
    "%R print(trim_logreg_model_7_summary)\n",
    "\n",
    "%R vif(trim_logreg_model_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a22ba",
   "metadata": {},
   "source": [
    "#### Model 7: Receiver Operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R p_trim_logreg_model_7 <- predict(trim_logreg_model_7, newdata=subset(test_r_df, select=c(2,3,4,5,8,26,28,67\\\n",
    "                                                                                            ,70)), type=\"response\")\n",
    "%R pr_trim_logreg_model_7 <- prediction (p_trim_logreg_model_7, test_r_df$deposit_num_map)\n",
    "%R prf_trim_logreg_model_7 <- performance(pr_trim_logreg_model_7, measure=\"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_trim_logreg_model_7)\n",
    "\n",
    "%R auc_trim_7 <- performance(pr_trim_logreg_model_7, measure=\"auc\")\n",
    "%R auc_trim_7 <- auc_trim_7@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c4bc9",
   "metadata": {},
   "source": [
    "#### Model 7 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024d711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R trim_logreg_model_test_7 <- predict(trim_logreg_model_7, newdata=subset(test_r_df, select=c(2,3,4,5,8,26\\\n",
    "                                                                                               ,28,67,70))\\\n",
    "                                       , type=\"response\")\n",
    "%R trim_logreg_model_test_7 <- ifelse(trim_logreg_model_test_7>0.5,1,0)\n",
    "%R misclasificerror_7 <- mean(trim_logreg_model_test_7!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6805c7b",
   "metadata": {},
   "source": [
    "##### **Model 7 Interpretation**\n",
    "Model 7 presents the \"best\" trimmed multiple logistic regression where the R application glm method is used to determine the deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from  `age`, `balance`, `campaign`, `previous_contact`, `job_entrepreneur`, `housing_yes`, `loan_no`, `month_dec`, and `month_mar` as the independent variables in a training subset (train_r_df) of the full trimmed and cleaned dataset (*N* = 34,360). The `default_yes` variable has been removed for model 7. The intercept was calculated to be -1.8210. \\\n",
    "The regression coefficient for `age` is -0.00954 with a statistically significant *p*-value <.001. This means that as age increases, there is a slight decrease in the log odds (and by extension probability) of the client subscribing to a term deposit. Model 7 indicates that `age` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `balance` is 0.00019 with a statistically significant *p*-value <.001. This means that as average yearly balance in Euros increases, there is a slight increase in the log odds (and by extension probability) of the client subscribing to a term deposit. Model 7 indicates that `balance` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `campaign` is -0.1267 with a statistically significant *p*-value <.001. This means that as campaign increases, there is a decrease in the log odds of the client subscribing to a term deposit. Model 7 indicates that `campaign` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `previous_contact` is 1.06442 with a statistically significant *p*-value <.001. This means that based on whether there was previous there is a moderate increase in the log odds of the client subscribing to a term deposit. Model 7 indicates that `previous_contact` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `job_entrepreneur` is -0.29379 with a statistically significant *p*-value <.05. This means that when a person's job is entrepreneur, there is a slight decrease in the log odds of the client subscribing to a term deposit. Model 7 indicates that `job_entrepreneur` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `housing_yes` is -0.99772 with a statistically significant *p*-value <.001. This means that people with a housing loan, decrease the log odds of the client subscribing to a term deposit. Model 6 indicates that `housing_yes` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `loan_no` is 0.53737 with a statistically significant *p*-value <.001. This means that people without a personal loan, increase the log odds of the client subscribing to a term deposit. Model 7 indicates that `loan_no` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `month_dec` is 0.92773 with a statistically significant *p*-value <.001. This means that people who were last contacted about the deposit in December, increase the log odds of the client subscribing to a term deposit. Model 7 indicates that `month_dec` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `month_mar` is 1.59689 with a statistically significant *p*-value <.001. This means that people who were last contacted about the deposit in march, increase the log odds of the client subscribing to a term deposit. Model 7 indicates that `month_mar` is significant in determining the deposit status. \\\n",
    "The ROC was then plotted to calcuate the AUC. The AUC for model 7 is equal to 0.7150, so the area under the ROC covers about 72% of the rectangle, indicating that model 7 has a moderate predictive ability. The accuracy of model 7 is equal to 0.8805, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 7 is the best of the 8 models produced in its ability to predict deposit status. So, when `age`, `balance`, `camapaign`, `previous_contact`, `job_entrepreneuer`, `housing_yes`, `loan_no`, `month_dec`, and `month_mar` are used to predict deposit status, it produces the best of the models, since all the predictors have a significant effect on deposit status. Something to note: While this model produces the best results compared to our other models, model 7 still doesn't have great predictive ability of deposit status overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb333f-8949-4aaf-9a83-e2e1a61e1dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Model 7b: Trimmed Multiple Regression \n",
    "(deposit ~ age+balance+campaign+previous-contact+job_entrepreneuer+housing_yes+loan_no+month_dec+month_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263d60c-05ab-4fb6-ae3f-c5b9a468f077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#final model on subset where \"yes\" ~40% of sample!!#\n",
    "%R trim_logreg_model_7b <- glm(deposit_num_map ~ age +balance + campaign + previous_contact\\\n",
    "                               + job_entrepreneur + housing_yes + loan_no + month_dec\\\n",
    "                               + month_mar, data=train_r_df2, family=binomial())\n",
    "%R print(trim_logreg_model_7b)\n",
    "\n",
    "%R trim_logreg_model_7b_summary <- summary(trim_logreg_model_7b)\n",
    "%R print(trim_logreg_model_7b_summary)\n",
    "\n",
    "%R vif(trim_logreg_model_7b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541ec4c-2de4-48fe-82bf-f67456cb21f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model 7b: Receiver Operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bc3df-3230-42ac-a38b-d12c40f3be00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%R p_trim_logreg_model_7b <- predict(trim_logreg_model_7b, newdata=subset(test_r_df2, select=c(2,3,4,5,8,26,28\\\n",
    "                                                                                               ,67,70))\\\n",
    "                                     , type=\"response\")\n",
    "%R pr_trim_logreg_model_7b <- prediction (p_trim_logreg_model_7b, test_r_df2$deposit_num_map)\n",
    "%R prf_trim_logreg_model_7b <- performance(pr_trim_logreg_model_7b, measure=\"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_trim_logreg_model_7b)\n",
    "\n",
    "%R auc_trim_7b <- performance(pr_trim_logreg_model_7b, measure=\"auc\")\n",
    "%R auc_trim_7b <- auc_trim_7b@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa3f67-618c-43dc-89f0-057469dcd6ce",
   "metadata": {},
   "source": [
    "#### Model 7b Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R trim_logreg_model_test_7b <- predict(trim_logreg_model_7b, newdata=subset(test_r_df2, select=c(2,3,4,5,8\\\n",
    "                                                                                                  ,26,28,67,70))\\\n",
    "                                        , type=\"response\")\n",
    "%R trim_logreg_model_test_7b <- ifelse(trim_logreg_model_test_7b>0.5,1,0)\n",
    "%R misclasificerror_7b <- mean(trim_logreg_model_test_7b!=test_r_df2$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_7b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cdfd5d",
   "metadata": {},
   "source": [
    "#### Model 8: Trimmed Multiple Logistic Regression (deposit ~ balance+campaign+previous_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%R trim_logreg_model_8 <- glm(deposit_num_map ~ balance + campaign + previous_contact, data=train_r_df\\\n",
    "                              , family=binomial())\n",
    "%R print(trim_logreg_model_8)\n",
    "\n",
    "%R trim_logreg_model_8_summary <- summary(trim_logreg_model_8)\n",
    "%R print(trim_logreg_model_8_summary)\n",
    "\n",
    "%R vif(trim_logreg_model_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e571162f",
   "metadata": {},
   "source": [
    "#### Model 8: Receiver Operator Curve & Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b0e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R p_trim_logreg_model_8 <- predict(trim_logreg_model_8, newdata=subset(test_r_df, select=c(3,4,5)), type=\"response\")\n",
    "%R pr_trim_logreg_model_8 <- prediction (p_trim_logreg_model_8, test_r_df$deposit_num_map)\n",
    "%R prf_trim_logreg_model_8 <- performance(pr_trim_logreg_model_8, measure=\"tpr\", x.measure=\"fpr\")\n",
    "%R plot(prf_trim_logreg_model_8)\n",
    "\n",
    "%R auc_trim_8 <- performance(pr_trim_logreg_model_8, measure=\"auc\")\n",
    "%R auc_trim_8 <- auc_trim_8@y.values[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b5012e",
   "metadata": {},
   "source": [
    "#### Model 8 Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b9172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R trim_logreg_model_test_8 <- predict(trim_logreg_model_8, newdata=subset(test_r_df, select=c(3,4,5)), type=\"response\")\n",
    "%R trim_logreg_model_test_8 <- ifelse(trim_logreg_model_test_8>0.5,1,0)\n",
    "%R misclasificerror_8 <- mean(trim_logreg_model_test_8!=test_r_df$deposit_num_map)\n",
    "%R print(paste('Accuracy', 1-misclasificerror_8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffa9de",
   "metadata": {},
   "source": [
    "##### **Model 8 Interpretation**\n",
    "Model 8 presents a trimmed multiple logistic regression where the R application glm method is used to determine the deposit status (i.e., \"yes\" or \"no\") as the dependent variable values from `balance`, `campaign`, and `previous_contact` as the independent variables in a training subset (train_r_df) of the full trimmed and cleaned dataset (*N* = 34,360). Model 8 looks at the relationship between three of the numerical predictors and deposit status. The intercept was calculated to be -2.1950. \\\n",
    "The regression coefficient for `balance` is 0.00023 with a statistically significant *p*-value <.001. This means that as average yearly balance in Euros increases, there is a slight increase in the log odds (and by extension probability) of the client subscribing to a term deposit. Model 8 indicates that `balance` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `campaign` is -0.12150 with a statistically significant *p*-value <.001. This means that as campaign increases, there is a decrease in the log odds of the client subscribing to a term deposit. Model 8 indicates that `campaign` is significant in determining the deposit status. \\\n",
    "The regression coefficient for `previous_contact` is 0.09879 with a statistically significant *p*-value <.001. This means that based on whether there was previous contact there is a slight increase in the log odds of the client subscribing to a term deposit. Model 8 indicates that `previous_contact` is significant in determining the deposit status. \\\n",
    "The ROC was then plotted to calcuate the AUC. The AUC for model 8 is equal to 0.6626, so the area under the ROC covers about 66% of the rectangle, indicating that model 8 has a weak predictive ability. The accuracy of model 8 is equal to 0.8786, which is high but does not necessarily indicate a well-fitted model due to the low value of the AUC. \\\n",
    "In summary, model 8's ability to predict deposit is weak, most likely due to the fact that there are excluded variables that have an affect on deposit status. This model was created to show how soley the numeric variables affect deposit status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2347a8",
   "metadata": {},
   "source": [
    "##### **Overall Results & Summary**\n",
    "Several models were developed to reduce the number of features to a manageable amount and attempt to find the model with the highest chance of accurately predicting the binary outcome of the `deposit` variable (dependent feature). Models 1-3 were simple logistic regression models comparing one response variable to one predictor variable. As outlined under each model above, none of them were sufficiently predictive to be contenders for the final and most useful model. Models 4-8 used multiple independent variables with the idea that their combinations would be better at predicting the binary result than any one of them alone. Model 4 was the largest model and included 73 independent variables. The large number was due to a large number of categorical variables that were discretized by generating dummy variables, and moreover, several of the nominal variables had several individual categories (e.g., after transforming \"unknown\" values for job and education, they had 11 and 4 categories respectively). Model 4 was run to see if all variables included would generate a good predictive model, but after doing so, it only had an accuracy of 88.15%, which was only slightly higher than the overall ratio of \"yes\" in the full cleaned and trimmed dataset (87.96%; *N* = 34,360). For model 5, the number of predictor variables was reduced to 65 by eliminating those variables (relative to model 4) that were determined to be perfectly linearly dependent on other independent variables (namely, `job_housemaid`, `marital_divorced`, `education_unknown`, `default_no`, `housing_no`, `loan_yes`, `day_31`, `month_sep`), as indicated by a regression coefficient of \"NA\". Module 6 was reduced relative to model 5 down to 10 independent variables by eliminating any variables with a variance inflation factor (VIF) greater than 2.5. This was done to further avoid possible multi-collinearity with other independent variables. Model 6 had a *p*-value of .1356 for `default_yes`, so it was eliminated for model 7 and 7b--as these latter models were determined to be the best from our analyses, there are discussed further below. For one last model (model 8), solely the \"naturally\" numerical variables were used to see if they alone would provide a sufficient model. It was found that the accuracy was 87.86% and AUC was 0.6626 which did not make for a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d2aa0",
   "metadata": {},
   "source": [
    "##### **Final Models**\n",
    "Model 7 used the following predictor variables along with the corresponding regression coefficients: `age` (-0.0095), `balance` (0.0002), `campaign` (-0.1267), `previous_contact` (1.0644), `job_entrepreneur` (-0.2938), `housing_yes` (-0.9977), `loan_no` (0.5374), `month_dec` (0.9277), and `month_mar` (1.5969). Intercept = -1.8210. After reviewing all of the models, it was determined that model 7 had the best combination of accuracy (88.05%), AUC (0.7150), and interpretability. Though the AUC was closer to 0.5 than 1.0, it was somewhat close to the models with the best overall AUC (models 4 & 5 AUC = 0.7458). Obviously this does not make it good, per se, but given the predictability of all models, it was mid- to high-level relatively. \\\n",
    "In terms of interpreting the model, as age increased there was a slight reduction in the probability of being able to predict deposit as “yes” and with an increase in balance, probability rose a little; both coefficients are slight. An increase in the number of contacts during the campaign actually decreased the probability, which makes sense if considering that people might be frustrated at being contacted more and would then be less likely to do business with that bank. However, whether the person did have any previous contact (“yes” or “no”) did seem to have relatively high positive impact. Also interesting was that whether or not the person’s job was entrepreneur had a negative affect—it should be noted that since only one job type was included, the only interpretation for this model that can be made is based on whether someone was an entrepreneur or not (i.e., a binary distinction, such that all other job types were lumped together into a “not-entrepreneur” category). This could be because as the job of entrepreneur there may be large fluctuations in income due to whether their current ventures are going well or not. Whether someone had a housing loan or didn’t have a personal loan also had an impact on the probability of predicting deposit as “yes”. This makes sense from the angle that a housing loan indicates a substantial outlay of income (thereby increasing probability that additional funds are not available to make a deposit), but a personal loan may be the opposite in effect. Lastly, whether the contact month was December, March, or other has had an impact. One possibility is that those were high volume banking months based on holiday bonuses received (in December) as well as preparation and saving for summer vacations (in March), and that contact in those months would remind people to open deposit accounts close to when they actually needed a specific place to keep funds. \\\n",
    "Model 7b was an attempt to mitigate the fact that the “yes” value in the full trimmed and cleaned dataset represented only 12.04% of the sample. As one additional step, the records with “yes” were pulled out, the n was divided by a fractional signifier (.4 in this case) to achieve a total desired n such that the ratio of “yes” to “no” was 40%. The set that contained only “no” values was then randomly sampled to pull out the number of records such that they would represent 60% of the total sample (1 - .4). Then using that dataset (*n* = 10,345) the same process that model 7 went through was performed: namely, it was split into a train and test subsets, and then a model was created using the same independent variables, as follows with regression coefficients: `age` (-0.0148), `balance` (0.0002), `campaign` (-0.1324), `previous_contact` (1.034*), `job_entrepreneur` (-0.3484), `housing_yes` (-0.9395), `loan_no` (0.5553), `month_dec` (1.296*), and `month_mar` (1.874*). Intercept = -0.0847. * Rounding due to RPY2 output in scientific notation. The intercept decreased significantly, and the two month-related coefficients increased relatively significantly. However, the accuracy and AUC actually decreased (68.14% and 69.39% respectively) relative to model 7, so in the end, model 7b was worse at predicting the probability of the dependent variable compared to model 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61a434-240a-4d8d-b22c-0d3c1b47148e",
   "metadata": {},
   "source": [
    "##### **Strengths & possible limitations of the current analyses**\n",
    "There were several strengths to the dataset. The size of the dataset (*N* = 45,211) meant that there would be sufficient data to develop a regression model using both a training set and a testing set. Additionally, both Python and R were used, which provided the ability to utilize each program for its strengths; Python's numpy and pandas libarries were used for the pre-processing due their speed and efficient, and R was used to generate the logistic regression models and generate several of the corresponding visualizations. With the trimming models used, multicollinearity was sufficiently addressed to avoid interaction or interdependence between predictor variables. \\\n",
    "There were also several factors that may have contributed a bias to the results. Initially a heavy cleaning of the data was required, which removed 20.86% of the data and also required filling in missing values (e.g., for age), and transforming ambigous values (e.g., changing \"unknown\" value in job to other values based on the modes of grouped data); taking a slightly different approach my have resulted in different outcomes. Another limitation may have been the available ratio of categorical values in some of the columns--for instance, if the number of yes's and no's in binary variable column were not even, it may have meant that the model again did not have sufficient compartive sample for each value to develop a robust predictive model. Lastly, there were a lot of variables to choose from initially to build the model--most of which may be a predictor of the dependent variables--but also several of them were categorical variables (some of which had several categories) that had to be discretized to be used in the model building process, all of which meant that including all of the dummy variables there were more than 70 to choose from to develop the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55544dc7-e8bc-4c52-9f09-287b9c709f74",
   "metadata": {},
   "source": [
    "##### **Future directions**\n",
    "Explore addition classification methods to obtain a better predictive model that was achieved using logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a388747-6c92-45d2-9de8-b1440dded459",
   "metadata": {},
   "source": [
    "***\n",
    "**References:** \\\n",
    "* Coban, H. (2019). Here's how I used Python to build a regression model using an e-commerce dataset. https://searchengineland.com/heres-how-i-used-python-to-build-a-regression-model-using-an-e-commerce-dataset-326493 \\\n",
    "* Devore, J. L. (2016). *Probability and statistics*. (9th ed.). Cengage Learning. \\\n",
    "* Mukala, M. M. (2012). A guide to appropriate use of correlation coefficient in medical research. Malawi Medical Journal, 24(3), 69-71. \\\n",
    "* Real Python. (n.d.). Linear regression in python. https://realpython.com/linear-regression-in-python/ \\\n",
    "* Real Python. (n.d.). Logistic regression in python. https://realpython.com/logistic-regression-python/ \\\n",
    "* Shah, C. (2020). *A hands-on introduction to data science*. Cambridge University Press. \\\n",
    "* Stack Overflow. (n.d.). GroupBy pandas dataFrame and select most common value. https://stackoverflow.com/questions/15222754/groupby-pandas-dataframe-and-select-most-common-value \\\n",
    "* UCLA: Statistical Consulting Group. Introduction to SAS. https://stats.idre.ucla.edu/sas/modules/sas-learning-moduleintroduction-to-the-features-of-sas/ (accessed December 12, 2021).\\\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
